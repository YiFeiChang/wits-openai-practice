{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b1e5e99-3966-402a-bddd-b6fcf5e1a5fd",
   "metadata": {},
   "source": [
    "# 結業測驗與認證：基於 RAG 的對談系統"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ffeac1-98ba-4aa2-ac4e-b194058ca9a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 背景說明："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9049d7-f1d2-4fe1-98a0-3656b120be09",
   "metadata": {},
   "source": [
    "作為 AI 工程師職位的候選人，請建立一個基於檢索輔助生成（Retrieval-Augmented Generation，RAG）的對談系統。此系統能根據提供的文字及表格來回答問題。以下提供了一個來自城市交通分析數據集的範例表格，您的系統必須能準確地從中檢索資訊並生成回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9d96d4-075a-4c7d-8960-4e53c798aa8b",
   "metadata": {},
   "source": [
    "## 問題："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0eb0e5-d61e-4a00-8ccf-e898c7c50a32",
   "metadata": {},
   "source": [
    "建立一個 RAG 對話系統，能夠處理以下表格資訊，並能準確回答下列問題：\n",
    "- 「請問台北市大安區與中正區的自行車占比率為多少？」"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e5bd58-b821-42d3-8cf0-e3c4b8afd049",
   "metadata": {},
   "source": [
    "## 該系統應展示以下能力："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8ac3d-3240-4ec2-8d23-a8954c98037a",
   "metadata": {},
   "source": [
    "1. 能夠處理文件中的文字與表格內容。\n",
    "2. 基於內容準確提取資訊並生成自然語言的回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f4ec4d-7f9e-4832-bd1d-2707d74c3797",
   "metadata": {},
   "source": [
    "## 交付項目："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0aff67-af1c-4740-81e9-775ef08c498a",
   "metadata": {},
   "source": [
    "- 一個展示您所建系統的 Jupyter Notebook。\n",
    "- 一個展示設計過程與架構的簡報，包括：\n",
    "  - 系統架構\n",
    "  - 設計選擇\n",
    "- 您如何解決文件和圖像數據的 RAG 整合問題。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b54f4-d93a-4d3f-ba6e-1c6e9a3ac5cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 各運具類別市佔率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9241f2-0751-41a9-b3bd-39e764c65326",
   "metadata": {},
   "source": [
    "![各運具類別市佔率](test.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1cfbc-422c-4472-9eef-bf7b8475bdf5",
   "metadata": {},
   "source": [
    "# 實作 - 處理文件中的文字與表格內容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e792d-4999-4375-93a7-65e4273e5096",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## jpg 轉存成 json 檔案"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa61557a-f556-4351-bc9c-aa03647b4fd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 載入類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2900834-99f7-41d1-a3ef-40b69fc8afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import base64\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000949da-5cca-4ac8-be3f-a71b123f5075",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 讀取 env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed30ef-4ba9-4164-97ad-c7e1f5fd6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "wits_gpt_endpoint = os.getenv(\"WITS_GPT_ENDPOINT\")\n",
    "wits_gpt_apikey = os.getenv(\"WITS_GPT_API_KEY\")\n",
    "wits_gpt_apiversion = os.getenv(\"WITS_GPT_API_VERSION\")\n",
    "wits_gpt_model = os.getenv(\"WITS_GPT_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aec26c-3789-4fc1-a111-cd7133bd25bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 定義 Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11535405-fae8-42c0-9e06-706935fdf651",
   "metadata": {},
   "source": [
    "#### 將 image 轉成 base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6951e392-e32a-4055-bcd4-871a1cc095e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_path):\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbf9b3-1b56-4f0f-99e2-4d8b7d29539a",
   "metadata": {},
   "source": [
    "#### 建立 image message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af75db9-d615-43a1-ad84-5c9484a80126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_message(base64_image):\n",
    "    return {\n",
    "        \"type\": \"image_url\",\n",
    "        \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c52d66-eb68-4d90-a995-125756229787",
   "metadata": {},
   "source": [
    "#### 從 message 抓出 json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ab894-0e54-4602-9adf-a42b8823eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_to_json(json_content):\n",
    "    pattern = r'```json\\s*\\n(.*?)\\n\\s*```'\n",
    "    match = re.search(pattern, json_content, re.DOTALL)\n",
    "    if match:\n",
    "        json_content = match.group(1)\n",
    "        return json_content\n",
    "    else:\n",
    "        print(\"未找到 json block\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6f3b91-28ae-40dc-8645-b5fabee48f95",
   "metadata": {},
   "source": [
    "#### 將 image 轉成 json 並存檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccbf4bf-ae2f-4d73-bd59-cdd2c0245eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_save_to_json(image_path):\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_endpoint=wits_gpt_endpoint,\n",
    "        openai_api_key=wits_gpt_apikey,\n",
    "        deployment_name=wits_gpt_model,\n",
    "        openai_api_version=wits_gpt_apiversion,\n",
    "        temperature=0\n",
    "    )\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: Image file not found at {image_path}.\")\n",
    "        return\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "    if not base64_image:\n",
    "        print(\"Error: Failed to encode image\")\n",
    "        return\n",
    "    image_message = create_image_message(base64_image)\n",
    "    messages = [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"請幫我解析這張圖片中的表格，並轉換為 json 格式。過濾掉 ```\\s*?\\(\\d+?\\)```。\n",
    "                    JSON 格式參考：\n",
    "                    ```\n",
    "                    [\n",
    "                        {\n",
    "                            \"District\": \"大安區\",\n",
    "                            \"綠運輸\": 72.9,\n",
    "                            \"公共運具\": 51.3,\n",
    "                            \"非機動運具\": 21.6,\n",
    "                            \"步行\": 17.7,\n",
    "                            \"自行車\": 3.8,\n",
    "                            \"私人機動運具\": 27.1,\n",
    "                            \"最常公共運具使用率\": 62.1\n",
    "                        },\n",
    "                        ...\n",
    "                    ]\n",
    "                    ```\n",
    "\n",
    "                    輸出放到 json 區塊中：\n",
    "                    ```json\n",
    "                    {json_content}\n",
    "                    ```\n",
    "                    \"\"\"\n",
    "                },\n",
    "                image_message\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        chain = llm | StrOutputParser()\n",
    "        print(\"正在將圖片傳送至 GPT...\")\n",
    "        response = chain.invoke(messages)\n",
    "        json_table = message_to_json(response)\n",
    "        print(\"\\n轉換結果：\")\n",
    "        print(json_table)\n",
    "        output_file = \"output_table.json\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(json_table)\n",
    "        print(f\"JSON 表格已保存至 {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"處理過程中發生錯誤: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3ac74-ea2e-4bc1-b27a-2c3da0292adc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 執行轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467706a7-19f0-4b71-855d-b44ab7f9b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_save_to_json(\"test.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d4b4bd-3384-4156-96d3-2ca928b1998b",
   "metadata": {},
   "source": [
    "## 將 json 檔案存入 VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2ca33b-af70-4253-a146-209ff7948bb6",
   "metadata": {},
   "source": [
    "### 讀取 json 檔案\n",
    "https://python.langchain.com/docs/integrations/document_loaders/json/\n",
    "https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html#langchain_core.vectorstores.in_memory.InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf1a7c3-d607-4414-8777-84816e2a1f37",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 安裝 Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78990fa3-7cb2-48da-879f-e2e5b37a6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain_community jq langchain-openai langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5f75b-1972-424e-a5d8-841d5c99db8d",
   "metadata": {},
   "source": [
    "#### 載入類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdbe8a8-0be7-442b-b163-1546f9571d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb312c2c-2a92-4450-b8e5-a15cff088b61",
   "metadata": {},
   "source": [
    "#### 讀取 env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d4733-b618-4682-85dc-c615ccb520b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "wits_gpt_endpoint = os.getenv(\"WITS_GPT_ENDPOINT\")\n",
    "wits_gpt_apikey = os.getenv(\"WITS_GPT_API_KEY\")\n",
    "wits_gpt_apiversion = os.getenv(\"WITS_GPT_API_VERSION\")\n",
    "wits_gpt_model = os.getenv(\"WITS_GPT_MODEL\")\n",
    "\n",
    "wits_embedding_endpoint = os.getenv(\"WITS_EMBEDDING_ENDPOINT\")\n",
    "wits_embedding_apikey = os.getenv(\"WITS_EMBEDDING_API_KEY\")\n",
    "wits_embedding_apiversion = os.getenv(\"WITS_EMBEDDING_API_VERSION\")\n",
    "wits_embedding_model = os.getenv(\"WITS_EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562537a-6e22-40d6-8a9e-5837bf735f25",
   "metadata": {},
   "source": [
    "#### 定義 function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32122aa-5589-4cee-862f-48d84e3d6b0b",
   "metadata": {},
   "source": [
    "##### 初始化 JSONLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5f459-aadb-46cd-bee5-53f0878b207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_jsonloader(json_path):\n",
    "    def metadata_func(record: dict, metadata: dict) -> dict:\n",
    "        metadata = record\n",
    "        return metadata\n",
    "        \n",
    "    return JSONLoader(\n",
    "        file_path=json_path,\n",
    "        jq_schema='.[]',\n",
    "        content_key='.District',\n",
    "        is_content_key_jq_parsable=True,\n",
    "        text_content=False,\n",
    "        metadata_func=metadata_func\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f15c5-6e20-4a9f-805f-39a4212d12cf",
   "metadata": {},
   "source": [
    "##### 初始化 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66846b1-53e7-4275-85b0-88fc4315554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_embeddings():\n",
    "    return AzureOpenAIEmbeddings(\n",
    "        azure_endpoint=wits_embedding_endpoint,\n",
    "        azure_deployment=wits_embedding_model,\n",
    "        openai_api_version=wits_embedding_apiversion,\n",
    "        api_key=wits_embedding_apikey\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0f792-75fe-4843-a66f-2244a7add7cc",
   "metadata": {},
   "source": [
    "##### 初始化 InMemoryVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4430130c-27bc-4e53-a031-b65d602a7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vectorstore(embeddings):\n",
    "    return InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917e0ef1-513a-44ae-9110-78a859b97597",
   "metadata": {},
   "source": [
    "#### 執行載入 JSON 並存入 VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9dc34-144d-4b4e-af83-44cc2bbdac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = init_jsonloader('output_table.json')\n",
    "documents = loader.load()\n",
    "embeddings = init_embeddings()\n",
    "vectorstore = init_vectorstore(embeddings)\n",
    "vectorstore.add_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74733887-f450-4941-8cb9-59d152b68dcc",
   "metadata": {},
   "source": [
    "# Chat Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fab0b1-7a55-4a95-ac82-b16e0d24d5c3",
   "metadata": {},
   "source": [
    "step 1 .   圖轉文 -> 文轉向量 -> 存進向量資料庫  \n",
    "step 2 . user 打的問題 -> 轉向量 -> 向量資料庫比對抓出最接近的資料 -> 塞prompt 給語言模型 -> 回應給user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28297851-85f7-4cfa-9978-1060e589dd64",
   "metadata": {},
   "source": [
    "## 安裝 Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba5882-875a-488e-81f3-e8683690ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain-core langgraph>0.2.27 langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdf1cc-bbbe-46c2-bc63-089e8972cea9",
   "metadata": {},
   "source": [
    "## 載入類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b1e33b-05d4-4890-ac80-eaa45fef7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage, trim_messages, filter_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, END, MessagesState, StateGraph\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ada8cd-1a46-4bbe-88c3-60dcb089bb11",
   "metadata": {},
   "source": [
    "## 讀取 env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f797635c-a552-4853-b19a-c1418d2d5623",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "wits_gpt_endpoint = os.getenv(\"WITS_GPT_ENDPOINT\")\n",
    "wits_gpt_apikey = os.getenv(\"WITS_GPT_API_KEY\")\n",
    "wits_gpt_apiversion = os.getenv(\"WITS_GPT_API_VERSION\")\n",
    "wits_gpt_model = os.getenv(\"WITS_GPT_MODEL\")\n",
    "\n",
    "wits_embedding_endpoint = os.getenv(\"WITS_EMBEDDING_ENDPOINT\")\n",
    "wits_embedding_apikey = os.getenv(\"WITS_EMBEDDING_API_KEY\")\n",
    "wits_embedding_apiversion = os.getenv(\"WITS_EMBEDDING_API_VERSION\")\n",
    "wits_embedding_model = os.getenv(\"WITS_EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3be3e62-dcb0-4cce-8d27-a7e8ae85e0a9",
   "metadata": {},
   "source": [
    "## 定義 function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0686635c-d323-42e3-b8ce-fc79ed7af810",
   "metadata": {},
   "source": [
    "### 初始化 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52bcc976-3578-4fd2-b9bd-5027656edd70",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def init_llm():\n",
    "    return AzureChatOpenAI(\n",
    "        azure_endpoint=wits_gpt_endpoint,\n",
    "        openai_api_key=wits_gpt_apikey,\n",
    "        api_version=wits_gpt_apiversion,\n",
    "        azure_deployment=wits_gpt_model\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb7ed37-ffc4-4c68-8cfe-58204b432e80",
   "metadata": {},
   "source": [
    "### 初始化 StateGraph (CompiledStateGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b7bb00e-1750-4fc2-acf9-4b04a2c0852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def init_state_graph(llm, prompt_template, tools):\n",
    "    def _call_model(state: MessagesState):\n",
    "        _trimmed_messages = trim_messages(\n",
    "            state[\"messages\"],\n",
    "            strategy=\"last\",\n",
    "            token_counter=len,\n",
    "            max_tokens=5,\n",
    "            start_on=\"human\",\n",
    "            end_on=(\"human\", \"tool\"),\n",
    "            include_system=True,\n",
    "        )\n",
    "        _agent_executor = create_react_agent(llm, tools)\n",
    "        _chain = prompt_template | _agent_executor\n",
    "        _response = _chain.invoke({\"messages\": _trimmed_messages})\n",
    "        return {\"messages\": _response['messages']}\n",
    "    _graph = StateGraph(state_schema=MessagesState)\n",
    "    _graph.add_edge(START, \"model\")\n",
    "    _graph.add_node(\"model\", _call_model)\n",
    "    _memory = MemorySaver()\n",
    "    return _graph.compile(checkpointer=_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c65fbc4-b2ea-454f-bd9a-4b560a34dfa3",
   "metadata": {},
   "source": [
    "## 開始聊天  \n",
    "你是負責問答任務的助手。使用以下檢索到的 context 來回答問題。如果你不知道答案，就說你不知道。最多使用三個句子並保持答案簡潔。  \n",
    "Question: {question}  \n",
    "Context: {context}  \n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b18e22c0-f338-4b58-8791-d71d8517639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "\n",
    "# We'll make a temporary directory to avoid clutter\n",
    "working_directory = TemporaryDirectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cff8339c-d136-460b-b93d-604143541ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = FileManagementToolkit(\n",
    "    # root_dir=str(working_directory.name)\n",
    ")  # If you don't provide a root_dir, operations will default to the current working directory\n",
    "tools = toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a306ae0-aa04-4ac3-a31c-570aac1f8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\"你是話少的助手。最多使用三個句子回答。\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "388b63df-641c-4905-9169-ad1bc3aac843",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_llm()\n",
    "llm = llm.bind_tools(tools)\n",
    "graph = init_state_graph(llm, prompt_template, tools)\n",
    "config = {\"configurable\": {\"thread_id\": \"test_thread\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72a438dd-4349-4645-9cb0-a588d9dfb95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "檔案 \"text.txt\" 已建立，並成功寫入內容。\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# query = \"請問台北市大安區與中正區的自行車市占率為多少？\"\n",
    "query = f'建立一個 \"text.txt\" 檔案，並寫入 \"{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}: 寫入測試\"。'\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = graph.invoke({\"messages\": input_messages}, config)\n",
    "\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23d6f3-9ff8-4f77-86cf-a98c1a2a861b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c8276-5e1a-4c28-89eb-25cf5a07e3b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d8480-a480-4af7-9453-18b2b906b2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee9ea8-4e28-4e73-966f-36e809f1d6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169d088-1406-4189-8df9-dd17e4004cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c5b05-6c0e-495d-8e0e-23f1701afbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696d7de-8061-4141-a61c-e92792655321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd0438-1502-4d04-8055-6d52306d7b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0a198e-22e3-4d1e-8c6f-69b76a8f441e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
